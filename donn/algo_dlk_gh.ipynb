{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uttam\\Anaconda3\\envs\\py35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import algos\n",
    "    import utils_m\n",
    "    import os\n",
    "    import datetime\n",
    "    import pytz\n",
    "    import itertools as it\n",
    "    import gc\n",
    "    from pymongo import MongoClient\n",
    "    import pickle\n",
    "except ImportError:\n",
    "    print(\"Required modules not installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ThresholdedReLU, ELU\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model as keras_load_model\n",
    "from keras import regularizers, optimizers\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"db_stockml\"\n",
    "bot_name = \"bot_m_algo_dlk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(bot, data, status):\n",
    "    client = MongoClient()\n",
    "    db = client[db_name]\n",
    "    c_bots = db[\"c_bots\"]\n",
    "    x = db.c_bots.update_one({\"bot_name\":bot}, {\"$set\":{\"status\": status, \"status_datetime\":pytz.timezone('Asia/Kolkata').localize(datetime.datetime.now()), \"data\":data}})\n",
    "    client.close()\n",
    "    del client, db, c_bots\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, filename):\n",
    "    with open(str(\"flag_\" + filename + \".txt\"), \"r\") as g:\n",
    "        check = g.read()\n",
    "    if check == \"open\":\n",
    "        print(\"file %s open\" % filename)\n",
    "        time.sleep(5)\n",
    "        return save_data(data, filename)\n",
    "    with open(str(\"flag_\" + filename + \".txt\"), \"w\") as f:\n",
    "        f.write(\"open\")\n",
    "    with open(str(\"flag_\" + filename + \".txt\"), \"r\") as g:\n",
    "        check = g.read()\n",
    "    if check == \"close\":\n",
    "        print(\"file %s open\" % filename)\n",
    "        time.sleep(5)\n",
    "        return save_data(data, filename)\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    with open(str(\"flag_\" + filename + \".txt\"), \"w\") as f:\n",
    "        f.write(\"close\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    with open(str(\"flag_\" + filename + \".txt\"), \"r\") as g:\n",
    "        check = g.read()\n",
    "    if check == \"open\":\n",
    "        print(\"file %s open\" % filename)\n",
    "        time.sleep(5)\n",
    "        return read_data(filename)\n",
    "    with open(str(\"flag_\" + filename + \".txt\"), \"w\") as f:\n",
    "        f.write(\"open\")\n",
    "    with open(str(\"flag_\" + filename + \".txt\"), \"r\") as g:\n",
    "        check = g.read()\n",
    "    if check == \"close\":\n",
    "        print(\"file %s open\" % filename)\n",
    "        time.sleep(5)\n",
    "        return read_data(filename)\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    with open(str(\"flag_\" + filename + \".txt\"), \"w\") as f:\n",
    "        f.write(\"close\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_status(db_stockml, c_bots, bot_name, message):\n",
    "    x = db_stockml.c_bots.update_one({\"bot_name\":bot_name}, {\"$set\":{\"status\": message, \"status_datetime\":pytz.timezone('Asia/Kolkata').localize(datetime.datetime.now())}})\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLK(algos.Algo):        \n",
    "    \n",
    "    # Initialize instance\n",
    "    def __init__(self, mode, name=\"dlk\", data=None, bot=None, data_filename=\"deep_optimized_networks_data.pickle\"):\n",
    "        super(DLK, self).__init__(mode)\n",
    "        \n",
    "        # If data is not supplied, create it\n",
    "        if data != None:\n",
    "            self.data = data\n",
    "        else:\n",
    "            self.data = {\"stage\":0, \"data_filename\":data_filename}\n",
    "            \n",
    "        if self.data[\"stage\"] == 0:\n",
    "            self.data = {\"combs\":{}, \"combs_comp\":{}, \"best_score\":{}, \"best_params\":{}, \"grids\":{}, \"stage\":0}\n",
    "            self.data[\"optimized\"] = False\n",
    "            self.data[\"name\"] = name\n",
    "            self.data[\"output_layer_units\"] = 1 \n",
    "            self.data['base_range'] = {\"i_layer_units\":{\"range\":[1,500], \"min\":1},\n",
    "                               \"h_layer_1_units\":{\"range\":[1,500], \"min\":1},\n",
    "                               \"h_layer_2_units\":{\"range\":[1,500], \"min\":1},\n",
    "                               \"h_layer_3_units\":{\"range\":[1,500], \"min\":1},\n",
    "                               \"activation\":{\"range\":['tanh']},\n",
    "                               \"optimizer\":{\"range\":['RMSprop']},\n",
    "                               \"batch_size\":{\"range\":[64], \"min\":8},\n",
    "                               \"epochs\":{\"range\":[10], \"min\":2},\n",
    "                               \"dropout_rate\":{\"range\":[0], \"min\":0.05}\n",
    "                              }\n",
    "        if bot != None:\n",
    "            self.data[\"bot_name\"] = bot\n",
    "        else:\n",
    "            self.data[\"bot_name\"] = bot_name\n",
    "        try:\n",
    "            self.data[\"run_id\"]\n",
    "        except KeyError:\n",
    "            self.data[\"run_id\"] = utils_m.generate_run_id(db_name)\n",
    "        \n",
    "        self.data[\"stage\"] = 1\n",
    "        save_data(self.data[\"bot_name\"], self.data, \"running\")\n",
    "            \n",
    "#         self.data['base_range'] = {\"no_of_hidden_layers\":2,\n",
    "#                            \"units\":{\"type\":\"int\", \"range\":[1,100]},\n",
    "#                            \"activation\":{\"type\":\"str\", \"range\":['tanh', 'elu', 'softsign']},\n",
    "#                            \"optimizer\":{\"type\":\"str\", \"range\":['RMSprop', 'Adagrad', 'Adam']},\n",
    "#                            \"batch_size\":{\"type\":\"int\", \"range\":[32, 512]},\n",
    "#                            \"epochs\":{\"type\":\"int\", \"range\":[10, 100]},\n",
    "#                            \"dropout\":{\"type\":\"str\", \"range\":['no','yes']},\n",
    "#                            \"dropout_rate\":{\"type\":\"float\", \"range\":[0,1]}\n",
    "#                           }\n",
    "        # Testing    \n",
    "#         self.data['base_range'] = {\"i_layer_units\":{\"type\":\"int\", \"range\":[1,500], \"min\":1},\n",
    "#                            \"h_layer_1_units\":{\"type\":\"int\", \"range\":[1,500], \"min\":1},\n",
    "#                            \"h_layer_2_units\":{\"type\":\"int\", \"range\":[1,500], \"min\":1},\n",
    "#                            \"h_layer_3_units\":{\"type\":\"int\", \"range\":[1,500], \"min\":1},\n",
    "#                            \"activation\":{\"type\":\"str\", \"range\":['tanh']},\n",
    "#                            \"optimizer\":{\"type\":\"str\", \"range\":['RMSprop']},\n",
    "#                            \"batch_size\":{\"type\":\"int\", \"range\":[64], \"min\":8},\n",
    "#                            \"epochs\":{\"type\":\"int\", \"range\":[10], \"min\":2},\n",
    "#                            \"dropout_rate\":{\"type\":\"float\", \"range\":[0], \"min\":0.05}\n",
    "#                           }\n",
    "        # Testing    \n",
    "#         self.data['base_range'] = {\"i_layer_units\":{\"type\":\"int\", \"range\":[10,10], \"min\":1},\n",
    "#                            \"h_layer_1_units\":{\"type\":\"int\", \"range\":[8,10], \"min\":1},\n",
    "#                            \"h_layer_2_units\":{\"type\":\"int\", \"range\":[10,10], \"min\":1},\n",
    "#                            \"h_layer_3_units\":{\"type\":\"int\", \"range\":[10,10], \"min\":1},\n",
    "#                            \"activation\":{\"type\":\"str\", \"range\":['tanh']},\n",
    "#                            \"optimizer\":{\"type\":\"str\", \"range\":['RMSprop']},\n",
    "#                            \"batch_size\":{\"type\":\"int\", \"range\":[64], \"min\":8},\n",
    "#                            \"epochs\":{\"type\":\"int\", \"range\":[1], \"min\":2},\n",
    "#                            \"dropout_rate\":{\"type\":\"float\", \"range\":[0], \"min\":0.05}\n",
    "#                           }\n",
    "    \n",
    "    def get_param_type(self, param):\n",
    "        if \"layer\" in param:\n",
    "            return \"int\"\n",
    "        elif param == \"batch_size\" or param == \"epochs\":\n",
    "            return \"int\"\n",
    "        elif param == \"dropout_rate\":\n",
    "            return \"float\"\n",
    "        elif param == \"activation\" or param == \"optimizer\":\n",
    "            return \"str\"\n",
    "        else:\n",
    "            raise ValueError(\"unrecognized paramaeter: %s\" % param)\n",
    "    \n",
    "    def get_activation_layer(self, activation):\n",
    "        if activation == 'LeakyReLU':\n",
    "            return LeakyReLU()\n",
    "        if activation == 'PReLU':\n",
    "            return PReLU()\n",
    "        if activation == 'ELU':\n",
    "            return ELU()\n",
    "        if activation == 'ThresholdedReLU':\n",
    "            return ThresholdedReLU()\n",
    "\n",
    "        return Activation(activation)\n",
    "\n",
    "    def get_optimizer(self, name='Adadelta'):\n",
    "        if name == 'SGD':\n",
    "            return optimizers.SGD(clipnorm=1.)\n",
    "        if name == 'RMSprop':\n",
    "            return optimizers.RMSprop(clipnorm=1.)\n",
    "        if name == 'Adagrad':\n",
    "            return optimizers.Adagrad(clipnorm=1.)\n",
    "        if name == 'Adadelta':\n",
    "            return optimizers.Adadelta(clipnorm=1.)\n",
    "        if name == 'Adam':\n",
    "            return optimizers.Adam(clipnorm=1.)\n",
    "        if name == 'Adamax':\n",
    "            return optimizers.Adamax(clipnorm=1.)\n",
    "        if name == 'Nadam':\n",
    "            return optimizers.Nadam(clipnorm=1.)\n",
    "\n",
    "        return optimizers.Adam(clipnorm=1.)\n",
    "\n",
    "    def delete_old_model(self, n):\n",
    "        s = str(\"model_aglo_dlk-\" + str(n) + \"-\")\n",
    "        for i in os.listdir(os.getcwd()):\n",
    "            if s in i:\n",
    "                os.remove(os.path.join(os.getcwd(), i))\n",
    "        return None\n",
    "        \n",
    "    def train(self, x_train, y_train, x_val=None, y_val=None, params=None, loss='binary_crossentropy', metric='accuracy', verbose=1):\n",
    "        kernel_initializer='normal'\n",
    "        \n",
    "        model = Sequential()\n",
    "           \n",
    "        model.add(Dense(params[\"i_layer_units\"], input_dim=x_train.shape[1], kernel_initializer=kernel_initializer, kernel_regularizer=regularizers.l2(0.01)))\n",
    "        model.add(self.get_activation_layer(params[\"activation\"]))\n",
    "        if params[\"dropout_rate\"] > 0:\n",
    "            model.add(Dropout(params[\"dropout_rate\"]))\n",
    "\n",
    "        for i in range(0, sum(key.startswith(\"h_layer\") for key in params)):\n",
    "            s = str(\"h_layer_\" + str(i+1) + \"_units\")\n",
    "            if params[s] == 0:\n",
    "                continue\n",
    "            model.add(Dense(params[s], kernel_initializer=kernel_initializer, kernel_regularizer=regularizers.l2(0.01)))\n",
    "            model.add(self.get_activation_layer(params[\"activation\"]))\n",
    "            if params[\"dropout_rate\"] > 0:\n",
    "                model.add(Dropout(params[\"dropout_rate\"]))\n",
    "\n",
    "        model.add(Dense(self.data[\"output_layer_units\"], kernel_initializer=kernel_initializer, activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss=loss,\n",
    "                      optimizer=self.get_optimizer(params[\"optimizer\"]), \n",
    "                      metrics=[metric])\n",
    "        \n",
    "        if x_val == None or y_val == None:\n",
    "            model.fit(x_train, y_train,\n",
    "                      batch_size=params[\"batch_size\"],\n",
    "                      epochs=params[\"epochs\"],\n",
    "                      verbose=verbose,\n",
    "                      shuffle=True\n",
    "                     )\n",
    "        else:\n",
    "            model.fit(x_train, y_train,\n",
    "                      batch_size=params[\"batch_size\"],\n",
    "                      epochs=params[\"epochs\"],\n",
    "                      verbose=verbose,\n",
    "                      validation_data=(x_val, y_val),\n",
    "                      shuffle=True\n",
    "                     )\n",
    "        \n",
    "        del kernel_initializer\n",
    "        return model\n",
    "        \n",
    "    \n",
    "    def list_from_range(self, rn):\n",
    "        if rn[\"type\"] == \"int\" or rn[\"type\"] == \"float\":\n",
    "            if len(rn[\"range\"]) == 0 or len(rn[\"range\"]) > 2:\n",
    "                raise ValueError(\"wrong range length\")\n",
    "        if rn[\"type\"] == \"int\":\n",
    "            if len(rn[\"range\"]) == 1:\n",
    "                return rn[\"range\"]\n",
    "            mn = rn[\"min\"]\n",
    "            top = round(rn[\"range\"][1])\n",
    "            bottom = round(rn[\"range\"][0])\n",
    "            dif = top - bottom\n",
    "            if dif < 0:\n",
    "                raise ValueError(\"Second number in range should be greater than or equal to the first one\")\n",
    "            elif dif == 0:\n",
    "                return [top]\n",
    "            elif dif <= mn:\n",
    "                if bottom == top:\n",
    "                    return [top]\n",
    "                else:\n",
    "                    return [bottom, top]\n",
    "            elif dif <= 2:\n",
    "                return list(range(bottom,top+1))\n",
    "            else:\n",
    "                delta = int(dif/2)\n",
    "                return [bottom, round(((bottom + delta) + (top - delta))/2), top]\n",
    "        elif rn[\"type\"] == \"float\":\n",
    "            if len(rn[\"range\"]) == 1:\n",
    "                return rn[\"range\"]\n",
    "            mn = rn[\"min\"]\n",
    "            top = rn[\"range\"][1] + 0.0\n",
    "            bottom = rn[\"range\"][0] + 0.0\n",
    "            dif = top - bottom\n",
    "            if dif < 0:\n",
    "                raise ValueError(\"Second number in range should be greater than or equal to the first one\")\n",
    "            elif dif == 0:\n",
    "                return [top]\n",
    "            elif dif <= mn:\n",
    "                if bottom == top:\n",
    "                    return [top]\n",
    "                else:\n",
    "                    return [bottom, top]\n",
    "            else:\n",
    "                delta = dif/2\n",
    "                return [bottom, bottom + delta, top]\n",
    "        elif rn[\"type\"] == \"str\":\n",
    "            return rn[\"range\"]\n",
    "    \n",
    "    def process_combinations(self, combs):\n",
    "        r = []\n",
    "        for comb in combs:\n",
    "            c = {}\n",
    "            for p in comb.keys():\n",
    "                if p.startswith(\"i_layer\") or p.startswith(\"h_layer\") or self.data['base_range'][p][\"type\"] == \"int\":\n",
    "                    c[p] = int(comb[p])\n",
    "                elif self.data['base_range'][p][\"type\"] == \"str\":\n",
    "                    c[p] = comb[p]\n",
    "                elif self.data['base_range'][p][\"type\"] == \"float\":\n",
    "                    c[p] = float(comb[p])\n",
    "            r.append(c)\n",
    "        return r\n",
    "    \n",
    "    def generate_combinations(self, d):\n",
    "        r = {}\n",
    "        for key in d.keys():\n",
    "            r[key] = list(map(str, d[key]))\n",
    "        \n",
    "        keys, values = zip(*r.items())\n",
    "        combs = [dict(zip(keys, v)) for v in it.product(*values)]\n",
    "        return process_combinations(combs)\n",
    "                \n",
    "    def range_from_last(self, grid, b_params):\n",
    "        last = str(last)\n",
    "#         grid = self.data[\"grids\"][last]\n",
    "        new = {}\n",
    "        for p in grid.keys():\n",
    "            typ = self.get_param_type(p)\n",
    "            if typ == \"str\":\n",
    "                new[p] = {\"range\":[b_params[p]], \"type\":typ}\n",
    "            else:\n",
    "                minim = self.data[\"base_range\"][p][\"min\"]\n",
    "                loc = grid[p].index(b_params[p])\n",
    "                new[p] = {\"min\":minim}\n",
    "                if len(grid[p]) == 1:\n",
    "                    new[p][\"range\"] = [grid[p][loc], grid[p][loc]]\n",
    "                elif len(grid[p]) == 2:\n",
    "                    new[p][\"range\"] = [b_params[p], b_params[p]]\n",
    "                elif loc == 0:\n",
    "                    bottom = grid[p][loc] - (grid[p][loc+1] - grid[p][loc])/2\n",
    "                    if bottom <= self.data[\"base_range\"][p][\"range\"][0]:\n",
    "                        new[p][\"range\"] = [grid[p][loc], (grid[p][loc] + grid[p][loc+1])/2]\n",
    "                    else:\n",
    "                        new[p][\"range\"] = [bottom, (grid[p][loc] + grid[p][loc+1])/2]\n",
    "                elif loc == len(grid[p]) - 1:\n",
    "                    top = grid[p][loc] + (grid[p][loc] - grid[p][loc-1])/2\n",
    "                    if top >= self.data[\"base_range\"][p][\"range\"][1]:\n",
    "                        new[p][\"range\"] = [(grid[p][loc] + grid[p][loc-1])/2, grid[p][loc]]\n",
    "                    else:\n",
    "                        new[p][\"range\"] = [(grid[p][loc] + grid[p][loc-1])/2, top]\n",
    "                else:\n",
    "                    new[p][\"range\"] = [(grid[p][loc] + grid[p][loc-1])/2, (grid[p][loc] + grid[p][loc+1])/2]\n",
    "        return new\n",
    "    \n",
    "    def add_to_best_models(self, model, score):\n",
    "        with open('best_models_order.pickle', 'rb') as f:\n",
    "            best_models_order = pickle.load(f)\n",
    "        with open('best_models_train_shape.pickle', 'rb') as f:\n",
    "            best_models_train_shape = pickle.load(f)\n",
    "        for i in range(0, len(best_models_order)):\n",
    "            if score[\"pos_accuracy\"] > best_models_order[i]:\n",
    "                for j in range(len(best_models_order)-1, i, -1):\n",
    "                    best_models_order[j] = best_models_order[j-1]\n",
    "                    best_models_train_shape[j] = best_models_train_shape[j-1]\n",
    "                    os.remove(str(\"best_model-\" + str(j) + \"-m.model\"))\n",
    "                    os.rename(str(\"best_model-\" + str(j-1) + \"-m.model\"), str(\"best_model-\" + str(j) + \"-m.model\"))\n",
    "                best_models_order[i] = score[\"pos_accuracy\"]\n",
    "                best_models_train_shape[i] = self.x_train.shape\n",
    "#                 best_models_train_shape[i] = [3058, 32764]\n",
    "                model.save(str(\"best_model-\" + str(i) + \"-m.model\"))\n",
    "                with open('best_models_order.pickle', 'wb') as f:\n",
    "                    pickle.dump(best_models_order, f)\n",
    "                with open('best_models_train_shape.pickle', 'wb') as f:\n",
    "                    pickle.dump(best_models_train_shape, f)\n",
    "                break\n",
    "        return None\n",
    "    \n",
    "    def grid_from_comb(self, last, comb):\n",
    "        grids = self.data[\"grids\"][last]\n",
    "        for key in grids.keys():\n",
    "            check = 0\n",
    "            for key2 in grids[key].keys():\n",
    "                if comb[key2] in grids[key][key2]:\n",
    "                    check += 1\n",
    "            if check == len(grids[key]):\n",
    "                return grids[key]\n",
    "        raise ValueError(\"grid not found\")\n",
    "                    \n",
    "    \n",
    "    def run_comb(self, comb):\n",
    "        for k in range(0, self.level+1):\n",
    "            model = self.train(self.x_train, self.y_train, self.x_val, self.y_val, params=comb, loss=self.loss, metric=self.metric, verbose=self.verbose)\n",
    "            yp_test = model.predict(self.x_test)\n",
    "            if k == 0:\n",
    "                score = self.test_metric(self.y_test, yp_test)\n",
    "            else:\n",
    "                score = ((score * k) + self.test_metric(self.y_test, yp_test))/(k+1)\n",
    "        del yp_test, k\n",
    "        return model, score\n",
    "        \n",
    "    \n",
    "    def run_round(self, n):\n",
    "        n = str(n)\n",
    "        try:\n",
    "            self.data[\"combs\"][n]\n",
    "        except KeyError:\n",
    "            if int(n) == 1:\n",
    "                self.data[\"grids\"][n] = {}\n",
    "                for p in self.data['base_range'].keys():\n",
    "                    self.data[\"grids\"][n][p] = self.list_from_range(self.data['base_range'][p])\n",
    "                combinations = self.generate_combinations(self.data[\"grids\"][n])\n",
    "                \n",
    "            elif int(n) == 2:\n",
    "                self.data[\"grids\"][n] = {}\n",
    "                last = str(int(n)-1)\n",
    "                combinations = []\n",
    "                for key in self.data[\"best\"][last].keys():\n",
    "                    if int(n) == 2:\n",
    "                        grid = self.data[\"grids\"][last]\n",
    "                    else:\n",
    "                        grid = grid_from_comb(last, self.data[\"best\"][last][key])\n",
    "                    rn = self.range_from_last(grid, self.data[\"best\"][last][key])\n",
    "                    self.data[\"grids\"][n][key] = {}\n",
    "                    for p in rn.keys():\n",
    "                        self.data[\"grids\"][n][key][p] = self.list_from_range(rn[p])\n",
    "                    del rn\n",
    "                for key in self.data[\"grids\"][n].keys():\n",
    "                    c = self.generate_combinations(self.data[\"grids\"][n][key])\n",
    "                    combinations = combinations + c\n",
    "                combinations = get_unique_combinations(combinations)\n",
    "            \n",
    "            self.data[\"combs\"][n] = combinations\n",
    "            self.data[\"combs_comp\"][n] = []\n",
    "            self.data[\"best_score\"][n] = 0\n",
    "            save_data(self.data[\"bot_name\"], self.data, \"running\")\n",
    "#             with open('data_dlk.pickle', 'wb') as f:\n",
    "#                 pickle.dump(self.data, f)\n",
    "#                 print(\"Storing Combinations\")\n",
    "            del combinations\n",
    "        \n",
    "        if len(self.data[\"combs\"][n]) == len(self.data[\"combs_comp\"][n]):\n",
    "            return self\n",
    "        print(\"Round grid:\")\n",
    "        print(self.data[\"grids\"][n])\n",
    "        print(\"%s new combinations found. Trying them.\" % (len(self.data[\"combs\"][n]) - len(self.data[\"combs_comp\"][n])))\n",
    "        \n",
    "#         cores = os.cpu_count() - 1\n",
    "\n",
    "        for i in range(0, len(self.data[\"combs\"][n])):\n",
    "            comb = self.data[\"combs\"][n][i]\n",
    "\n",
    "            if comb in self.data[\"combs_comp\"][n]:\n",
    "                continue\n",
    "\n",
    "            print(\"Combination: %s\" % str(i+1))\n",
    "            print(datetime.datetime.now())\n",
    "            #print(comb)\n",
    "            model, score = self.run_comb(comb)\n",
    "            \n",
    "            if len(self.data[\"best\"][n]) < self.level:\n",
    "                self.data[\"best\"][n][str(score)] = comb\n",
    "            else:\n",
    "                min_score = sorted(map(float, self.data[\"best\"][n].keys()))[len(self.data[\"best\"][n])-1]\n",
    "                if score > min_score:\n",
    "                    self.data[\"best\"][n][str(score)] = comb\n",
    "                    del self.data[\"best\"][n][min_score]\n",
    "                    \n",
    "\n",
    "            if score > self.data[\"best_score\"][n]:\n",
    "                print(\"Best\")\n",
    "                #self.best_model = model\n",
    "                self.data[\"best_params\"][n] = comb\n",
    "                self.data[\"best_score\"][n] = score\n",
    "                self.delete_old_model(n)\n",
    "                model.save(str(\"model_aglo_dlk-\" + str(n) + \"-\" + str(inserted_id)))\n",
    "                print(comb)\n",
    "                print(score)\n",
    "                self.add_to_best_models(model, score)\n",
    "\n",
    "            self.data[\"combs_comp\"][n].append(comb)\n",
    "            save_data(self.data[\"bot_name\"], self.data, \"running\")\n",
    "#             with open('data_dlk.pickle', 'wb') as f:\n",
    "#                 pickle.dump(self.data, f)\n",
    "            del comb, model, score, inserted_id\n",
    "            gc.collect()\n",
    "                \n",
    "            \n",
    "        if len(self.data[\"combs\"][n]) == 1:\n",
    "            self.data[\"optimized\"] = True\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def optimize(self, x_train, y_train, x_test, y_test, x_val, y_val, loss='binary_crossentropy', metric='accuracy', test_metric=utils_m.all_accuracy, verbose=1, stages=None, data_label=None, label=None, max_rounds=1, level=1):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "        self.loss = loss\n",
    "        self.metric = metric\n",
    "        self.test_metric = test_metric\n",
    "        self.verbose = verbose\n",
    "        self.stages = stages\n",
    "        self.data_label = data_label\n",
    "        self.label = label\n",
    "        self.level = level\n",
    "        \n",
    "        rounds = list(map(int, self.data[\"combs\"].keys()))\n",
    "        if len(rounds) == 0:\n",
    "            c_round = 1\n",
    "        else:\n",
    "            rounds.sort()\n",
    "            c_round = rounds[len(rounds)-1]\n",
    "        \n",
    "        while c_round <= max_rounds:\n",
    "            if self.data[\"optimized\"] == True:\n",
    "                print(\"Best parameters found\")\n",
    "                break\n",
    "            print(\"Running round: %s\" % c_round)\n",
    "            self.run_round(c_round)\n",
    "            gc.collect()\n",
    "            c_round += 1\n",
    "        print(\"%s rounds of optimization completed\" % str(c_round-1))\n",
    "        return self\n",
    "        \n",
    "    def get_data(self):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {1:{0:\"a\",9:\"b\"}, 3:{8:\"a\", 9:\"b\"}, 2:{7:\"c\", 8:\"b\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(a.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
